{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Economy Data\n",
    "This information is provided by the U.S. Environmental Protection Agency, Office of Mobile Sources, National Vehicle and Fuel Emissions Laboratory.\n",
    "\n",
    "Attribute\tDescription\n",
    "Model\tVehicle make and model\n",
    "Displ\tEngine displacement - the size of an engine in liters\n",
    "Cyl\tThe number of cylinders in a particular engine\n",
    "Trans\tTransmission Type and Number of Gears\n",
    "Drive\tDrive axle type (2WD = 2-wheel drive, 4WD = 4-wheel/all-wheel drive)\n",
    "Fuel\tFuel Type\n",
    "Cert Region*\tCertification Region Code\n",
    "Sales Area**\tCertification Region Code\n",
    "Stnd\tVehicle emissions standard code (View Vehicle Emissions Standards here)\n",
    "Stnd Description*\tVehicle emissions standard description\n",
    "Underhood ID\tThis is a 12-digit ID number that can be found on the underhood emission label of every vehicle. It's required by the EPA to designate its \"test group\" or \"engine family.\" This is explained more here\n",
    "Veh Class\tEPA Vehicle Class\n",
    "Air Pollution Score\tAir pollution score (smog rating)\n",
    "City MPG\tEstimated city mpg (miles/gallon)\n",
    "Hwy MPG\tEstimated highway mpg (miles/gallon)\n",
    "Cmb MPG\tEstimated combined mpg (miles/gallon)\n",
    "Greenhouse Gas Score\tGreenhouse gas rating\n",
    "SmartWay\tYes, No, or Elite\n",
    "Comb CO2*\tCombined city/highway CO2 tailpipe emissions in grams per mile\n",
    "\n",
    "* Not included in 2008 dataset\n",
    "* Not included in 2018 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data:\n",
    "Using pandas, explore all_alpha_08.csv and all_alpha_18.csv in the Jupyter Notebook below to answer\n",
    "questions below the notebook about these characteristics of the datasets:\n",
    "\n",
    "- number of samples in each dataset\n",
    "- number of columns in each dataset\n",
    "- duplicate rows in each dataset\n",
    "- datatypes of columns\n",
    "- features with missing values\n",
    "- number of non-null unique values for features in each dataset\n",
    "- what those unique values are and counts for ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('all_alpha_08.csv') \n",
    "df_18 = pd.read_csv('all_alpha_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 2008 dataset\n",
    "df_08.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 2018 dataset\n",
    "df_18.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_08.shape)\n",
    "df_08.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_18.shape)\n",
    "df_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save progress for the next section\n",
    "df_08.to_csv('data_08.csv', index=False)\n",
    "df_18.to_csv('data_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Column Labels\n",
    "1. Drop extraneous columns\n",
    "Drop features that aren't consistent (not present in both datasets) or aren't relevant to our questions. Use pandas' drop function.\n",
    "\n",
    "#### Columns to Drop:\n",
    "- From 2008 dataset: 'Stnd', 'Underhood ID', 'FE Calc Appr', 'Unadj Cmb MPG'\n",
    "- From 2018 dataset: 'Stnd', 'Stnd Description', 'Underhood ID', 'Comb CO2'\n",
    "\n",
    "\n",
    "2. Rename Columns\n",
    "Change the \"Sales Area\" column label in the 2008 dataset to \"Cert Region\" for consistency.\n",
    "Rename all column labels to replace spaces with underscores and convert everything to lowercase. (Underscores can be much easier to work with in Python than spaces. For example, having spaces wouldn't allow you to use df.column_name instead of df['column_name'] to select columns or use query(). Being consistent with lowercase and underscores also helps make column names easy to remember.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Extraneous Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('all_alpha_08.csv') \n",
    "df_18 = pd.read_csv('all_alpha_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from 2008 dataset\n",
    "df_08.drop(['Stnd', 'Underhood ID', 'FE Calc Appr', 'Unadj Cmb MPG'], axis=1, inplace=True)\n",
    "\n",
    "# confirm changes\n",
    "df_08.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from 2018 dataset\n",
    "df_18.drop(['Stnd', 'Stnd Description', 'Underhood ID', 'Comb CO2'], axis=1, inplace=True)\n",
    "\n",
    "# confirm changes\n",
    "df_18.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Sales Area to Cert Region\n",
    "df_08.rename(columns={'Sales Area': 'Cert Region'}, inplace=True)\n",
    "\n",
    "# confirm changes\n",
    "df_08.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces with underscores and lowercase labels for 2008 dataset\n",
    "df_08.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "\n",
    "# confirm changes\n",
    "df_08.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm column labels for 2008 and 2018 datasets are identical\n",
    "df_08.columns == df_18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure they're all identical like this\n",
    "(df_08.columns == df_18.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces with underscores and lowercase labels for 2018 dataset\n",
    "df_18.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "\n",
    "# confirm changes\n",
    "df_18.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.to_csv('all_alpha_08.csv_edited.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.to_csv('all_alpha_18.csv_edited.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter, Drop Nulls, Dedupe:\n",
    "1. Filter\n",
    "For consistency, only compare cars certified by California standards. Filter both datasets using query to select only rows where cert_region is CA. Then, drop the cert_region columns, since it will no longer provide any useful information (we'll know every value is 'CA').\n",
    "\n",
    "2. Drop Nulls\n",
    "Drop any rows in both datasets that contain missing values.\n",
    "\n",
    "3. Dedupe\n",
    "Drop any duplicate rows in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('data_08.csv')\n",
    "df_18 = pd.read_csv('data_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "df_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Certification Region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter datasets for rows following California standards\n",
    "df_08 = df_08.query('cert_region == \"CA\"')\n",
    "df_18 = df_18.query('cert_region == \"CA\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm only certification region is California\n",
    "df_08['cert_region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm only certification region is California\n",
    "df_18['cert_region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop certification region columns form both datasets\n",
    "df_08.drop('cert_region', axis=1, inplace=True)\n",
    "df_18.drop('cert_region', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Rows with Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view missing value count for each feature in 2008\n",
    "df_08.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view missing value count for each feature in 2018\n",
    "df_18.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with any null values in both datasets\n",
    "df_08.dropna(inplace=True)\n",
    "df_18.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if any of columns in 2008 have null values - should print False\n",
    "df_08.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if any of columns in 2018 have null values - should print False\n",
    "df_18.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dedupe Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of duplicates in 2008 and 2018 datasets\n",
    "print(df_08.duplicated().sum())\n",
    "print(df_18.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates in both datasets\n",
    "df_08.drop_duplicates(inplace=True)\n",
    "df_18.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of duplicates again to confirm dedupe - should both be 0\n",
    "print(df_08.duplicated().sum())\n",
    "print(df_18.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save progress for the next section\n",
    "df_08.to_csv('data_08.csv', index=False)\n",
    "df_18.to_csv('data_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Data Types:\n",
    "In the next three sections, I'll make the following changes to make the datatypes consistent and practical to work with.\n",
    "\n",
    "Fix cyl datatype\n",
    "- 2008: extract int from string.\n",
    "- 2018: convert float to int.\n",
    "\n",
    "Fix air_pollution_score datatype\n",
    "- 2008: convert string to float.\n",
    "- 2018: convert int to float.\n",
    "\n",
    "Fix city_mpg, hwy_mpg, cmb_mpg datatypes\n",
    "- 2008 and 2018: convert string to float.\n",
    "\n",
    "Fix greenhouse_gas_score datatype\n",
    "- 2008: convert from float to int."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing cyl Data Type:\n",
    "- 2008: extract int from string\n",
    "- 2018: convert float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "df_08 = pd.read_csv('data_08.csv')\n",
    "df_18 = pd.read_csv('data_18.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value counts for the 2008 cyl column\n",
    "df_08['cyl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract int from strings in the 2008 cyl column\n",
    "df_08['cyl'] = df_08['cyl'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value counts for 2008 cyl column again to confirm the change\n",
    "df_08['cyl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 2018 cyl column to int\n",
    "df_18['cyl'] = df_18['cyl'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.to_csv('data_08.csv', index=False)\n",
    "df_18.to_csv('data_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing air_pollution_score Data Type:\n",
    "- 2008: convert string to float\n",
    "- 2018: convert int to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('data_08.csv')\n",
    "df_18 = pd.read_csv('data_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.iloc[582]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get all the hybrids in 2008\n",
    "hb_08 = df_08[df_08['fuel'].str.contains('/')]\n",
    "hb_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrids in 2018\n",
    "hb_18 = df_18[df_18['fuel'].str.contains('/')]\n",
    "hb_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two copies of the 2008 hybrids dataframe\n",
    "df1 = hb_08.copy()  # data on first fuel type of each hybrid vehicle\n",
    "df2 = hb_08.copy()  # data on second fuel type of each hybrid vehicle\n",
    "\n",
    "# Each one should look like this\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to split by \"/\"\n",
    "split_columns = ['fuel', 'air_pollution_score', 'city_mpg', 'hwy_mpg', 'cmb_mpg', 'greenhouse_gas_score']\n",
    "\n",
    "# apply split function to each column of each dataframe copy\n",
    "for c in split_columns:\n",
    "    df1[c] = df1[c].apply(lambda x: x.split(\"/\")[0])\n",
    "    df2[c] = df2[c].apply(lambda x: x.split(\"/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataframe holds info for the FIRST fuel type of the hybrid\n",
    "# aka the values before the \"/\"s\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataframe holds info for the SECOND fuel type of the hybrid\n",
    "# aka the values before the \"/\"s\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataframes to add to the original dataframe\n",
    "new_rows = df1.append(df2)\n",
    "\n",
    "# now we have separate rows for each fuel type of each vehicle!\n",
    "new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original hybrid rows\n",
    "df_08.drop(hb_08.index, inplace=True)\n",
    "\n",
    "# add in our newly separated rows\n",
    "df_08 = df_08.append(new_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all the original hybrid rows with \"/\"s are gone\n",
    "df_08[df_08['fuel'].str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two copies of the 2018 hybrids dataframe, hb_18\n",
    "df1 = hb_18.copy()\n",
    "df2 = hb_18.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split values for fuel, city_mpg, hwy_mpg, cmb_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to split\n",
    "split_columns = ['fuel', 'city_mpg', 'hwy_mpg', 'cmb_mpg']\n",
    "\n",
    "# apply split function to each column of each dataframe copy\n",
    "for c in split_columns:\n",
    "    df1[c] = df1[c].apply(lambda x: x.split(\"/\")[0])\n",
    "    df2[c] = df2[c].apply(lambda x: x.split(\"/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the two dataframes\n",
    "new_rows = df1.append(df2)\n",
    "\n",
    "# drop each hybrid row from the original 2018 dataframe\n",
    "# do this by using Pandas drop function with hb_18's index\n",
    "df_18.drop(hb_18.index, inplace=True)\n",
    "\n",
    "# append new_rows to df_18\n",
    "df_18 = df_18.append(new_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that they're gone\n",
    "df_18[df_18['fuel'].str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to float for 2008 air pollution column\n",
    "df_08.air_pollution_score = df_08.air_pollution_score.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert int to float for 2018 air pollution column\n",
    "df_18.air_pollution_score = df_18.air_pollution_score.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.to_csv('data_08.csv', index=False)\n",
    "df_18.to_csv('data_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `city_mpg`, `hwy_mpg`, `cmb_mpg` datatypes:\n",
    "    2008 and 2018: convert string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('data_08.csv')\n",
    "df_18 = pd.read_csv('data_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mpg columns to floats\n",
    "mpg_columns = ['city_mpg', 'hwy_mpg', 'cmb_mpg']\n",
    "for c in mpg_columns:\n",
    "    df_18[c] = df_18[c].astype(float)\n",
    "    df_08[c] = df_08[c].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert from float to int:\n",
    "df_08['greenhouse_gas_score'] = df_08['greenhouse_gas_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from float to int\n",
    "df_08['greenhouse_gas_score'] = df_08['greenhouse_gas_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.dtypes == df_18.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your new CLEAN datasets as new files!\n",
    "df_08.to_csv('clean_08.csv', index=False)\n",
    "df_18.to_csv('clean_18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring with Visuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "df_08 = pd.read_csv('clean_08.csv')\n",
    "df_18 = pd.read_csv('clean_18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the distributions of greenhouse gas score in 2008 and 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08['greenhouse_gas_score'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18['greenhouse_gas_score'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions are more skewed to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has the distribution of combined mpg changed from 2008 to 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08['cmb_mpg'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18['cmb_mpg'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Became much more skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the correlation between displacement and combined mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot \n",
    "df_18.plot(x='displ', y='cmb_mpg', kind='scatter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot \n",
    "df_18.plot(x='greenhouse_gas_score', y='cmb_mpg', kind='scatter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "df_08 = pd.read_csv('clean_08.csv')\n",
    "df_18 = pd.read_csv('clean_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Are more unique models using alternative sources of fuel? By how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.fuel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.fuel.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative sources of fuel available in 2008 are CNG and ethanol, and those in 2018 ethanol and electricity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique models used alternative sources of fuel in 2008\n",
    "alt_08 = df_08.query('fuel in [\"CNG\", \"ethanol\"]').model.nunique()\n",
    "alt_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique models used alternative sources of fuel in 2018\n",
    "alt_18 = df_18.query('fuel in [\"Ethanol\", \"Electricity\"]').model.nunique()\n",
    "alt_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"2008\", \"2018\"], [alt_08, alt_18])\n",
    "plt.title(\"Number of Unique Models Using Alternative Fuels\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Unique Models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2008, the number of unique models using alternative sources of fuel increased by 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total unique models each year\n",
    "total_08 = df_08.model.nunique()\n",
    "total_18 = df_18.model.nunique()\n",
    "total_08, total_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_08 = alt_08/total_08\n",
    "prop_18 = alt_18/total_18\n",
    "prop_08, prop_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"2008\", \"2018\"], [prop_08, prop_18])\n",
    "plt.title(\"Proportion of Unique Models Using Alternative Fuels\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Proportion of Unique Models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: How much have vehicle classes improved in fuel economy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_08 = df_08.groupby('veh_class').cmb_mpg.mean()\n",
    "veh_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_18 = df_18.groupby('veh_class').cmb_mpg.mean()\n",
    "veh_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much they've increased by for each vehicle class\n",
    "inc = veh_18 - veh_08\n",
    "inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plot the classes that exist in both years\n",
    "inc.dropna(inplace=True)\n",
    "plt.subplots(figsize=(8, 5))\n",
    "plt.bar(inc.index, inc)\n",
    "plt.title('Improvements in Fuel Economy from 2008 to 2018 by Vehicle Class')\n",
    "plt.xlabel('Vehicle Class')\n",
    "plt.ylabel('Increase in Average Combined MPG');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What are the characteristics of SmartWay vehicles? Have they changed over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartway labels for 2008\n",
    "df_08.smartway.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all smartway vehicles in 2008\n",
    "smart_08 = df_08.query('smartway == \"yes\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore smartway vehicles in 2008\n",
    "smart_08.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smartway labels for 2018\n",
    "df_18.smartway.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all smartway vehicles in 2018\n",
    "smart_18 = df_18.query('smartway in [\"Yes\", \"Elite\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_18.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: What features are associated with better fuel economy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_08 = df_08.query('cmb_mpg > cmb_mpg.mean()')\n",
    "top_08.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_18 = df_18.query('cmb_mpg > cmb_mpg.mean()')\n",
    "top_18.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Datasets:\n",
    "\n",
    "Use Pandas Merges to create a combined dataset from clean_08.csv and clean_18.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_08 = pd.read_csv('clean_08.csv')\n",
    "df_18 = pd.read_csv('clean_18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 2008 columns\n",
    "df_08.rename(columns=lambda x: x[:10] + \"_2008\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view to check names\n",
    "df_08.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "df_combined = df_08.merge(df_18, left_on='model_2008', right_on='model', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view to check merge\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('combined_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new dataframe, model_mpg, that contain the mean combined mpg values in 2008 and 2018 for each unique model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import pandas as pd\n",
    "\n",
    "new_df = pd.read_csv('combined_dataset.csv')\n",
    "new_df.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new column, mpg_change, with the change in mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['mpg_change'] = new_df['cmb_mpg_2008'] - new_df['cmb_mpg']\n",
    "#new_df.insert(1, 'mpg_change',int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the vehicle that improved the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['mpg_change'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " new_df.query('mpg_change == 6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Cheverolet Impala"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
